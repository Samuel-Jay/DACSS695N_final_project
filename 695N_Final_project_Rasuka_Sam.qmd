---
title: "Spotify Artist Feature Collaboration Network Analysis"
subtitle: "DACSS 695N Social Network Analysis"
author: "Rasuka Shrestha/ Samuel Jayachandran"
date: "April 25, 2024"
format: 
  html:
    toc: true
    toc-depth: 2
    toc-title: Contents
    toc-location: left
    code-fold: false
    html-math-method: katex
    theme: flatly
    smooth-scroll: true
    link-external-icon: true
    link-external-newwindow: true
    citations-hover: true
    footnotes-hover: true
    font-size: 80%
editor: visual
---

# Spotify artist feature collaboration network analysis

## Introduction:

This study is a network analysis that tries to identify, quantify and evaluate the relationship between follower counts of each artist's various collaborators vs the artist's own success in the charts. The presumed hypothesis is that popular artists will probably have many successful chart hits (hence why they're popular), therefore any successful/complete collaboration that another artist has with them for an album is likely to reach very high in an extremely competitive chart ranking.

```{r}
library(moderndive)
library(olsrr)
library(tidyr)
library(tidyverse)
library(sna)
library(igraph)
library(network)
library(infer)
library(intergraph)
library(stringr)
library(readr)
library(ggnetwork)
library(readxl)
```

These are the necessary packages to do our network analysis.

Charting high in an under-competitive ranking is not the same as ranking high in a highly competitive chart. So rank values should be weighted by the competitiveness. It is logical to assume that a ranking is competitive if: 1) that genre of music is highly popular, 2) the artists are highly popular, 3) due to 1 and 2 there would be a massive influx of many artists to that category/genre and also to that particular chart's song collection.

Assessing the competitiveness in a numerical manner requires another metric involving popularity/follower counts of artists, and number of artists producing music in that genre.

### Data cleaning

```{r}
edges <- read_csv("edges.csv")
edges <- na.omit (edges)

nodes <- read.csv("nodes.csv")
nodes <- na.omit (nodes)
nodes <- nodes %>% distinct(spotify_id, .keep_all = TRUE)

HP <- nodes %>% filter(((str_detect(genres, "hip hop")) & (str_detect(chart_hits, "us")) & (followers > 5000000)))
# hiphop <- left_join(edges, nodes, by = join_by(id_0 == spotify_id))
# hiphop <- left_join(hiphop, nodes, by = join_by(id_1 == spotify_id))
# hiphop <- hiphop %>% filter(((str_detect(genres.x, "hip hop")) | (str_detect(genres.y, "hip hop"))) &
#                             ((str_detect(chart_hits.x, "us")) | (str_detect(chart_hits.y, "us"))))

# pop <- left_join(edges, nodes, by = join_by(id_0 == spotify_id))
# pop <- left_join(pop, nodes, by = join_by(id_1 == spotify_id))
# pop <- pop %>% filter(((str_detect(genres.x, "pop")) | (str_detect(genres.y, "pop"))) &
#                             ((str_detect(chart_hits.x, "us")) | (str_detect(chart_hits.y, "us"))))

# HP <- nodes %>% filter(((str_detect(genres, "hip hop"))) & (str_detect(chart_hits, "us")))
# HP <- HP %>% filter(followers > 5000000)

```

### First problem:

```{r}
full_net <- graph_from_edgelist(as.matrix(edges))
mean(degree(full_net))
```

There are 153k nodes/artists in the network and 300k collaborations between them, the average degree of the network from the edgelist should be less than 2 (it says 3.918 up there). The node attribute list has 156k entries, don't know if they are duplicates or artists who just didn't collaborate with anyone.

## Converting to 2-mode network to compare in-genre collab rate vs cross-genre collab:

We will now take the subgenres of hip hop and look at which artists belong to which subgenres. Then we can compare the collaboration within a subgenre vs between different subgenres. We can also then compare the popularity of in-genre collaborators vs cross-genre collaborators.

## Adjacency matrix of each artist analyzed here:

```{r}
edges <- edges %>% filter((edges$id_0 %in% HP$spotify_id) &
                            (edges$id_1 %in% HP$spotify_id))

# Get unique collaborations and their frequencies
unique_collaborations <- table(paste(edges$id_0, edges$id_1))

# Get unique names of individuals
all_names <- unique(c(edges$id_0, edges$id_1))

# Create an empty adjacency matrix
adj_matrix <- matrix(0, nrow = length(all_names), ncol = length(all_names), dimnames = list(all_names, all_names))

# Fill in the adjacency matrix with collaboration frequencies
for (collab in names(unique_collaborations)) {
  names <- unlist(strsplit(collab, " "))
  from <- names[1]
  to <- names[2]
  adj_matrix[from, to] <- unique_collaborations[collab]
  adj_matrix[to, from] <- unique_collaborations[collab]
}

# Print the adjacency matrix
# print(adj_matrix)
```

```{r}
collab_graph <- graph_from_adjacency_matrix(adj_matrix, mode = "undirected",
                                            diag = FALSE)
```

```{r}
HP <- HP %>% filter(HP$spotify_id %in% all_names)

V(collab_graph)$name <- HP$name
V(collab_graph)$followers <- HP$followers
V(collab_graph)$genres = HP$genres
```

```{r, fig.height=25,fig.width=25}


plot(
  collab_graph, 
  vertex.size = 5,
  vertex.label.cex = 0.5,
  layout = layout_with_fr,
  vertex.shapes = ifelse((str_detect(V(collab_graph)$genres, "hip hop") & !(str_detect(V(collab_graph)$genres, "pop"))), "square", "circle")
)

```

```{r}
#degree_centralities <- c(length(HP$spotify_id))

#for (i in 1:nrow(HP)) {
 #   degree_centralities[i] <- degree(collab_graph, v = V(collab_graph)[i], loops = FALSE)
  #}
#followers <- V(collab_graph)$followers
#degree_centralities <- as.matrix(degree_centralities)
#dat1 <- data.frame(degree_centralities, followers)

#relation1 <- lm(followers ~ degree_centralities, data = dat1)

#summary(relation1)

#neighbors_followcounts <- c(length(HP$spotify_id))

#for (i in 1:nrow(HP)) {
 # neighbors_followcounts[i] <- sum(neighbors(collab_graph, V(collab_graph)[i])$followers)
#}
#followers <- V(collab_graph)$followers
#neighbors_followcounts <- as.matrix(neighbors_followcounts)
#dat2 <- data.frame(neighbors_followcounts, followers)

#relation2 <- lm(followers ~ neighbors_followcounts, data = dat2)

#summary(relation2)

#V(collab_graph)$popularity <- HP$popularity

#summary(lm(popularity ~ followers, data = HP))

#popularity <- V(collab_graph)$popularity
#neighbors_popularity <- c(length(HP$spotify_id))

#for (i in 1:nrow(HP)) {
 # neighbors_popularity[i] <- sum(neighbors(collab_graph, V(collab_graph)[i])$popularity)
#}
#neighbors_popularity <- as.matrix(neighbors_popularity)
#dat3 <- data.frame(neighbors_popularity, popularity)

#relation3 <- lm(popularity ~ neighbors_popularity, data = dat3)

#summary(relation3)

#dat4 <- data.frame(degree_centralities, popularity)

#relation4 <- lm(popularity ~ degree_centralities, data = dat4)

#summary(relation4)
```

All these regression analyses yielded no significant results, except for the obvious fact that popularity and follower count are strongly correlated. Intuitively, artists that collaborate with more people would be listened to (and followed by) by all their collaborators' fans. But the p-values for every coefficient were well above any threshold of statistical significance (\~0.8 or \~0.5 \>\> 0.05), indicating no correlation.

So we 're gonna be looking at other network centrality vs follower counts and popularity for each node.

```{r}
dist_mat = distances(collab_graph)
diag(dist_mat) <-  NA
mean(dist_mat, na.rm = T)
median(dist_mat, na.rm = T)
close_mat <- 1/dist_mat
mean(close_mat, na.rm = T)
median(close_mat, na.rm = T)
```

So there is a finite distance from every node to every other node as evidenced by the fact that the mean(distances) is 2.07

```{r}
closeness_measure <- closeness(collab_graph, normalized = T)
distance_measure <- distances(collab_graph)
diag(distance_measure) <- NA
betweenness_measure <- betweenness(collab_graph, directed = FALSE, normalized = F)
ev_centrality <- eigen_centrality(collab_graph)$vector

centrality_popularity <- data.frame(names = HP$name,
                                  closeness_measure = closeness_measure,
                                  betweenness_measure = betweenness_measure,
                                  eigencentrality = ev_centrality,
                                  popularity = HP$popularity)

centrality_followers <- data.frame(names = HP$name,
                                  closeness_measure = closeness_measure,
                                  betweenness_measure = betweenness_measure,
                                  eigencentrality = ev_centrality,
                                  follcts = HP$followers)
```

```{r}
library(ggplot2)

clos_pop_plot <- ggplot(centrality_popularity, aes(x = closeness_measure, y = popularity)) +
  geom_point() +                                      
  geom_smooth(method = "lm", 
              formula = popularity ~ closeness_measure) +
  xlab("Closeness to other artists") + ylab("Popularity") +
 theme(axis.text = element_text(size = 6.5))
clos_pop_plot

between_pop_plot <- ggplot(centrality_popularity, aes(x = betweenness_measure, y = popularity)) +
  geom_point() +                                      
  geom_smooth(method = "lm", 
              formula = popularity ~ betweenness_measure) +
  xlab("Betweenness among artists") + ylab("Popularity") +
 theme(axis.text = element_text(size = 6.5))
between_pop_plot

evc_pop_plot <- ggplot(centrality_popularity, aes(x = eigencentrality, y = popularity)) +
  geom_point() +                                      
  geom_smooth(method = "lm", 
              formula = popularity ~ eigencentrality) +
  xlab("Eigenvector Centrality of artists") + ylab("Popularity") +
 theme(axis.text = element_text(size = 6.5))
evc_pop_plot

clos_foll_plot <- ggplot(centrality_followers, aes(x = closeness_measure, y = follcts)) +
  geom_point() +                                      
  geom_smooth(method = "lm", 
              formula = follcts ~ closeness_measure) +
  xlab("Closeness to other artists") + ylab("Follower counts of artists") +
 theme(axis.text = element_text(size = 6.5))
clos_foll_plot

between_foll_plot <- ggplot(centrality_followers, aes(x = betweenness_measure, y = follcts)) +
  geom_point() +                                      
  geom_smooth(method = "lm", 
              formula = follcts ~ betweenness_measure) +
  xlab("Betweenness among artists") + ylab("Follower count of artists") +
 theme(axis.text = element_text(size = 6.5))
between_foll_plot

evc_foll_plot <- ggplot(centrality_followers, aes(x = eigencentrality, y = follcts)) +
  geom_point() +                                      
  geom_smooth(method = "lm", 
              formula = follcts ~ eigencentrality) +
  xlab("Eigenvector Centrality of artists") + ylab("Follower count of artists") +
 theme(axis.text = element_text(size = 6.5))
evc_foll_plot
```

```{r}
centr_degree(collab_graph, loops = FALSE, normalized = TRUE)
```

```{r}
den_collabs <- density(degree(collab_graph), from = 0)
plot(range(den_collabs$x), range(den_collabs$y), 
     type = "n", xlab = "degree", 
     ylab = "density", 
     main = "Degree Distribution for Collaboration Network")

lines(den_collabs, col = "red" , lty = 2, lwd = 2)
```

## Cross-genre vs in-genre collaboration:

```{r}
# write.csv(HP, "HP.csv")
```

```{r}
# Was going to put each artist into one (or more) of the many subgenres of hip hop but community detection and analysis isn't for now.
```

```{r}
library(car)

cols <- recode(HP$genres, 
               as.factor = F, "'[A-Z]^ hip hop' = 'yellow'; NA = NA; else = 'orange'")

table(HP$genres, cols)

artist_collab_eb <- cluster_edge_betweenness(graph = collab_graph)

plot(artist_collab_eb, collab_graph, 
     col = cols, vertex.label = NA, layout = layout_with_drl, 
     main = "Genre Mapped onto Communities")
```

```{r}
proportion_function <- function(communities, attribute){ 
  
  # Arguments:
  # communities: vector of community membership
  # attribute: attribute vector

  # Here we calculate the proportion that fall into each category 
  # found in attribute. We first do a table and then find the proportion 
  # in each category. This is done for each community (using tapply 
  # over the communities).
  
  dat <- tapply(factor(attribute), communities, 
             function(x) {y <-  table(x); y / sum(y)})

  # We then output it as a matrix using do.call
  return(do.call(rbind, dat))
}
```

```{r}
mems_eb <- membership(collab_graph)
proportion_function(communities = mems_eb, attribute = HP$genre)
```

## Considerations that were impractical or not possible:

We were unable to get datasets where we could find the time of each collab between any combination of artists. So we cannot analyze temporal changes in relationships, how artist popularity changed with various collaborations etc.,.

With greater time, more access to Spotify APIs, we would be able to obtain time of each collaboration using the artists' ids, matching the name of the album/single (that the artists collaborated on) to the year that the particular album/single was released.

Then we could make comparisons between the follower count of each of the artists before and after the collaboration was done. This could be done with networkDynamic package and viewing the network before and after each new edge is formed between 2 artists.
